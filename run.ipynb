{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd141aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from parameters import *\n",
    "from prompt import *\n",
    "dataset_train = load_dataset('glue', DATASET, split='train')\n",
    "dataset_val = load_dataset('glue', DATASET, split='validation')\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8d8b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(examples):\n",
    "    if DATASET=='mnli':\n",
    "        return tokenizer(examples['premise'], examples['hypothesis'],  truncation=True, padding='max_length',max_length=128)\n",
    "    if DATASET=='qnli':\n",
    "        return tokenizer(examples['question'], examples['sentence'],  truncation=True, padding='max_length',max_length=128)\n",
    "    if DATASET=='qqp': \n",
    "        return tokenizer(examples['question1'], examples['question2'], truncation=True, padding='max_length',max_length=128)\n",
    "    if DATASET=='sst2': \n",
    "        return tokenizer(examples['sentence'],  truncation=True, padding='max_length',max_length=128)\n",
    "\n",
    "dataset_train = dataset_train.map(encode, batched=True)\n",
    "dataset_val = dataset_val.map(encode, batched=True)\n",
    "\n",
    "dataset_train = dataset_train.map(lambda examples: {'labels': examples['label']}, batched=True)\n",
    "dataset_val = dataset_val.map(lambda examples: {'labels': examples['label']}, batched=True)\n",
    "\n",
    "dataset_train.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=1)\n",
    "dataset_val.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
    "dataloader_val = torch.utils.data.DataLoader(dataset_val, batch_size=CLIENT_NUM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a185ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer,AutoConfig\n",
    "\n",
    "\n",
    "config=AutoConfig.from_pretrained(MODEL)\n",
    "model = BertPrefixForSequenceClassification.from_pretrained(MODEL) #BertPromptForSequenceClassification/BertForSequenceClassification\n",
    "\n",
    "from tqdm import tqdm \n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "model.train().to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LR)\n",
    "\n",
    "for name,para in model.named_parameters():\n",
    "    if 'prefix_encoder' not in name and 'classifier' not in name  and 'pooler' not in name :\n",
    "        para.requires_grad=False\n",
    "    else:\n",
    "        para.requires_grad=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4b9a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import *\n",
    "import numpy as np\n",
    "norm_l2=NORMCLIP\n",
    "eps=10.\n",
    "delta=1e-3  \n",
    "all_loss=0.\n",
    "for epoch in range(EPOCH):\n",
    "    last_update=model.state_dict()\n",
    "    current_update=[]\n",
    "    for i, batch in enumerate(tqdm(dataloader_train)):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        all_loss+=loss.data\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), NORMCLIP)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        current_update.append(model.state_dict())\n",
    "        model.load_state_dict(last_update)\n",
    "        if (i+1)%CLIENT_NUM==0:\n",
    "            new_state={x:torch.mean(torch.stack([update[x] for update in current_update],dim=0),dim=0) if (last_update[x].type is torch.float) else last_update[x] for x in last_update}\n",
    "            for name,p in model.named_parameters():\n",
    "                if p.grad is not None:\n",
    "                    # add equivalent noise after aggregation\n",
    "                    new_state[name] += torch.FloatTensor(np.random.normal(0, LR*2*NORMCLIP*np.sqrt(2*np.log(1.25/DELTA))/EPS/np.sqrt(CLIENT_NUM),size=p.grad.size())).to(device)\n",
    "            model.load_state_dict(new_state)\n",
    "            last_update=model.state_dict()\n",
    "            current_update=[] \n",
    "            \n",
    "        if i % (10*CLIENT_NUM) == 0:\n",
    "            print(f\"loss: {all_loss/(i+1)}\")\n",
    "    model.eval()  \n",
    "    all_pred=[]\n",
    "    all_label=[]\n",
    "    for i, batch in enumerate(tqdm(dataloader_val)):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        all_pred += np.argmax(outputs[1].detach().cpu().numpy(),axis=-1).tolist()\n",
    "        all_label+=batch['labels'].detach().cpu().numpy().tolist() \n",
    "    print(accuracy_score(all_label,all_pred))\n",
    "    model.train()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
